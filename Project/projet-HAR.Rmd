---
title: "Practical Machine Learning Project: Human Activity Recognition with Random Forest Algorithm"
author: "Gianfranco Schilirò"
date: "September 27, 2015"
output: html_document
---
## Abstract
In this project for Practical Machine Learning, a random forest model is built to predict human activity based on the observations collected in the Groupware@LES Human Activity Recognition dataset.

The Human Activity Recognition dataset contains accelerometer data collected from sensors on the belt, forearm, arm, and dumbbell from 6 participants that were asked to perform barbell lifts correctly and incorrectly in 5 different ways (sitting-down, standing-up, standing, walking, and sitting).
The **goal** is to predict the manner in which they did the exercise.

A **random forest model** was built with 250 trees using 5-fold cross-validation and achieved an accuracy on the validation data of 99.47% with an sample error of 0.53%.

Moreover, built, trained and validated the learning algorithm, we were predicted 20 new cases in the test set 20 with 100% accuracy.

## Work Enviroment 

* Set Work Directory. 
* Load the packages that I will use later.
```{r}
setwd("/home/gianfranco/workspace/Practical_Machine_Learning/Project")

load <- function(package){
  new.package <- package[!(package %in% installed.packages()[, "Package"])]
  if (length(new.package))
    install.packages(new.package, dependencies = TRUE)
  sapply(package, require, character.only = TRUE)
} 

packages <- c("caret", "randomForest", "rpart", "rpart.plot")
load(packages)
```
## Load the data  
* Load Training and Testing datasets from Human Activity Recognition (http://groupware.les.inf.puc-rio.br/har) 
```{r}
train_File <- "pml-training.csv"
test_File  <- "pml-testing.csv"

if (!file.exists(train_File)) {
  download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", destfile=train_File, method="curl",quiet=TRUE)
}

if (!file.exists(test_File)) {
  download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", destfile=test_File, method="curl",quiet=TRUE)
}

training <- read.csv(train_File)
testing <- read.csv(test_File)
```

## Explore datasets
```{r}
dim(training)
dim(testing)
```
The *Training Set* contains **19622 observations** and **160 variables** and the *Test Set* contains **20 observations** and **160 variables**.

It is a *Classification Problem*, therefore, the response variable is called **class** and consists of 5 factors, labeled A-E, representing the physical activities: *sitting-down, standing-up, standing, walking, and sitting*.

A summary gives us information on how the class response is distributed in the Training Set:
```{r}
summary(training$classe)
```
It is evident that in the training set there is no class skew

## Preprocess Data
* I need to drop columns with NAs, drop highly correlated variables and drop variables with 0 (or approx to 0) variance.

**Remove varables with NA’s**

The Training Set contains a lot of missing values, so we remove variables with NA’s:
```{r}
sum(complete.cases(training))

trainingCleaned <- training[, colSums(is.na(training)) == 0]
dim(trainingCleaned)
```

**Remove variables with near zero variance**

Variables with unique values e.g zero or near zero variance are removed as they have little or no impact on the response.
```{r}
nzv <- nearZeroVar(trainingCleaned, saveMetrics=TRUE)
trainingCleaned <- trainingCleaned[, nzv[,"nzv"] == FALSE]
dim(trainingCleaned)
```

**Remove low-informations columns**

Remove the variables that do not contain useful information for learning, such as timestamp, user_name, new_window etc.
```{r}
trainingCleaned <- trainingCleaned[, -grep("timestamp|user_name|new_window|num_window|X", names(trainingCleaned))]
dim(trainingCleaned)
```
The Cleaned Training Set now contains **19622 observations** and **53 variables**.

## Model
* A predictive model is fitted using Random Forest algorithm. with **5-fold cross validation** for a good bias-variance trade-off.
* I need to split the cleaned Training Set in two samples. **70%** for Training Set and **30%** for Cross Validation Set.
```{r}
set.seed(1234)
inTrain <- createDataPartition(trainingCleaned$classe, p=0.7, list=FALSE)
training <- trainingCleaned[inTrain,]
validation <- trainingCleaned[-inTrain, ]

timestamp(stamp = date(),
           prefix = "##------Start: ", suffix = " ------##",
           quiet = FALSE)

model <- train(classe ~ .,
                  data=training, method="rf",
                  trControl=trainControl(method="cv", number=5),
                  prox=TRUE,
                  ntree=250)

timestamp(stamp = date(),
           prefix = "##------ End: ", suffix = " ------##",
           quiet = FALSE)
model
```

## Accuracy and Error of the model
* The performance of the model is estimated on the Validation Set.  
```{r}
predict <- predict(model, validation)
confusionMatrix(validation$classe, predict)

accuracy <- postResample(predict, validation$classe)
accuracy
```
The out sample error should be low as the random forest algorithm performs cross-validation internally.
```{r}
err <- sum(predict != validation$classe) * 100 / nrow(validation)
```
* The estimated accuracy of the model is **`r round(confusionMatrix(validation$classe, predict)$overall[1]*100, 2)`%** and the estimated out sample error is **`r round(err, 2)`%**

## Predictions on the Testing Set
* The model is applied to the original Testing Set.
```{r, results='hide'}
testData <- testing[, names(testing) %in% names(trainingCleaned)]
result <- predict(model, newdata=testData)
result
```  
The selected model (Random Forest) was able to predict **100%** of the **20 cases** provided in the testing dataset.

## Tree and Graphs
```{r}
modelTree <- rpart(classe ~ ., data=trainingCleaned, method="class")
prp(modelTree) 
```

```{r}
top <- varImp(model)
plot(top, main = "Top 10 most influencial predictors", top = 10)
```

```{r}
plot(model, main="Accuracy Vs Predictors")
```

```{r}
plot(model$finalModel, main="Error rate Vs Number of Trees")
```

## Submission of Results
Apply machine learning algorithm for the prediction of the 20 test cases, and create the necessary files for the submission.
```{r}
featureset <- colnames(trainingCleaned)

pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}

testing_data <- testing[featureset[featureset!='classe']]
answers <- predict(model, newdata=testing_data)
answers

pml_write_files(answers)
```